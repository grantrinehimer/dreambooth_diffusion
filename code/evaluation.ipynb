{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c56fa570",
   "metadata": {},
   "source": [
    "# Subject-Driven Generation Metrics Evaluation\n",
    "\n",
    "##### We have a dataset of 30 distinct “subjects” (objects vs. live subjects/pets), split into:\n",
    "##### - **Real images**: stored under `data/<subject_name>/…`\n",
    "##### - **Generated images**: stored under `results/{non-ppl,ppl}/<subject_name>/…`\n",
    "\n",
    "##### We also have:\n",
    "##### - `data/subjects.csv` with columns:\n",
    "#####     - `subject_name` (matches each folder name)\n",
    "#####    - `class`        (e.g. “dog”, “backpack”, etc.)\n",
    "#####     - `live`         (boolean: True for pets, False for objects)\n",
    "##### - `data/prompts.csv` with columns:\n",
    "#####     - `prompt` (templates containing `{0}` → “sks”, `{1}` → the `class` value)\n",
    "#####     - `live`   (boolean: whether this prompt applies to live subjects or objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cffae19",
   "metadata": {},
   "source": [
    "\n",
    "##### **Evaluation protocol**:\n",
    "##### - We generated up to **2** samples per prompt in `ppl` and also **2** for `non-ppl`.\n",
    "##### - Metrics:\n",
    "#####     1. **PRES** (avg pairwise DINO similarity real↔gen)\n",
    "#####     2. **DIV**  (avg pairwise LPIPS distance among gen images)\n",
    "#####     3. **CLIP-I** (avg cosine between CLIP image embeddings real↔gen)\n",
    "#####     4. **CLIP-T** (avg cosine between CLIP text embeddings vs. gen images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e02ab91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from metrics import clip_embeddings, div, pres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fd1b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_df = pd.read_csv('../data/subjects.csv')\n",
    "prompts_df  = pd.read_csv('../data/prompts.csv')\n",
    "\n",
    "REAL_ROOT  = '../data'\n",
    "GEN_ROOT  = '../results'\n",
    "CONDITIONS = ['no_ppl', 'ppl']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c38830",
   "metadata": {},
   "source": [
    "#### Collecting CLIP-I, CLIP-T, PRES (between real and generated images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3101556e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for cond in CONDITIONS:\n",
    "    data_root = os.path.join(REAL_ROOT, cond)\n",
    "    res_root = os.path.join(GEN_ROOT, cond)\n",
    "    for _, row in subjects_df.iterrows():\n",
    "        subject = row['subject_name']\n",
    "\n",
    "        real_dir = os.path.join(data_root, subject)\n",
    "        gen_dir  = os.path.join(res_root, subject)\n",
    "        if not os.path.isdir(real_dir) or not os.path.isdir(gen_dir):\n",
    "            continue \n",
    "\n",
    "        preservation   = pres.collect_pres(real_dir, gen_dir)\n",
    "        clip_i, clip_t = None, None\n",
    "\n",
    "        results.append({\n",
    "            'condition': cond,\n",
    "            'subject':   subject,\n",
    "            'PRES':      preservation,\n",
    "            'CLIP-I':    clip_i,\n",
    "            'CLIP-T':    clip_t\n",
    "        })\n",
    "\n",
    "        print(f'{cond} {subject} {preservation:.4f}')\n",
    "\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ac4360",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"metric_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baaf5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = (\n",
    "    results_df\n",
    "    .merge(subjects_df, left_on='subject', right_on='subject_name')\n",
    "    .drop(columns=['subject_name']) \n",
    ")\n",
    "\n",
    "pivot = (\n",
    "    merged\n",
    "    .pivot_table(\n",
    "       index='class',\n",
    "       columns='condition',\n",
    "       values=['PRES','DIV','CLIP-I','CLIP-T'],\n",
    "       aggfunc='mean'\n",
    "    )\n",
    ")\n",
    "print(pivot)\n",
    "\n",
    "pivot.to_csv(\"average_metric_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a90c4c6",
   "metadata": {},
   "source": [
    "#### Collecting DIV (between generated images of the same class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3de82f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "div_values = []\n",
    "for cond in CONDITIONS:\n",
    "    for _, row in subjects_df.iterrows():\n",
    "        subject = row['subject_name']\n",
    "        gen_dir = os.path.join(GEN_ROOT, cond, subject)\n",
    "        if not os.path.isdir(gen_dir):\n",
    "            print(f\"Skipping {cond}/{subject}: directory not found\")\n",
    "            continue\n",
    "        v = div.collect_div(gen_dir)\n",
    "        print(f'{cond} {subject} {v:.4f}')\n",
    "        div_values.append({'condition': cond, 'subject': subject, 'DIV': v})\n",
    "\n",
    "div_df = pd.DataFrame(div_values)\n",
    "div_df.to_csv(\"../results/div_results.csv\", index=False)\n",
    "\n",
    "div_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c72683",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_div = (\n",
    "    div_df\n",
    "    .groupby('condition')['DIV']\n",
    "    .mean()\n",
    "    .reset_index(name='mean_DIV')\n",
    ")\n",
    "mean_div"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
